{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### fumction that uploads the HARP dataset from input_root in local machone and creates train and test data\n",
    "## Train and test files are saved to output root\n",
    "## train, test - initialized dataframes. \n",
    "## partitian is made with 70% train in 30% test\n",
    "#ind_test, ind_train - in case of partial run, can be used to save running time.\n",
    "## Feature Extraction\n",
    "def load_file(filepath):\n",
    "    column_names = ['Ax','Ay','Az']\n",
    "    dataframe = read_csv(filepath, header=None, names=column_names, delim_whitespace=True)\n",
    "#     get_num_from_path = re.findall(\"\\d\",filepath)\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def load_dataset(input_root,train,test,ind_train,ind_test):\n",
    "    files_list = glob.glob(input_root+'acc*.*')\n",
    "    column_names = ['exp_id','user_id','act_id','label_start','label_end']\n",
    "    labels = read_csv(input_root+'labels.txt', header=None, names=column_names, delim_whitespace=True)\n",
    "    X = labels[['exp_id','user_id','label_start','label_end']] \n",
    "    Y = labels['act_id']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "    #create_train_set\n",
    "    X_train = X_train.reset_index()\n",
    "    y_train = y_train.reset_index()\n",
    "    train = pd.DataFrame()\n",
    "    for i in np.arange(ind_train,len(X_train)):\n",
    "        #Validatin lenght of the segment so i will not be less then 2.56sec.\n",
    "        #Otherwise the segment is excluded from the data\n",
    "        if X_train.label_end[i]-X_train.label_start[i]>=129: \n",
    "            file_name='acc_exp{:0>2d}_user{:0>2d}.txt'.format(X_train.exp_id[i],X_train.user_id[i],y_train.act_id[i])\n",
    "            train = train.append(\n",
    "                featuer_extraction(input_root,file_name, X_train.label_start[i], X_train.label_end[i],y_train.act_id[i]),\n",
    "                ignore_index=True)\n",
    "        else:\n",
    "            print('sample_'+str(i)+'was excluded')\n",
    "    print('finish_train')\n",
    "\n",
    "    #create_test_set\n",
    "    X_test = X_test.reset_index()\n",
    "    y_test = y_test.reset_index()\n",
    "    test = pd.DataFrame()\n",
    "    for i in np.arange(ind_test,len(X_test)):\n",
    "        #Validatin lenght of the segment so i will not be less then 2.56sec.\n",
    "        #Otherwise the segment is excluded from the data\n",
    "        if X_test.label_end[i]-X_test.label_start[i]>=129:\n",
    "            file_name='acc_exp{:0>2d}_user{:0>2d}.txt'.format(X_test.exp_id[i],X_test.user_id[i],y_test.act_id[i])\n",
    "            test = test.append(\n",
    "                featuer_extraction(input_root,file_name, X_test.label_start[i], X_test.label_end[i],y_test.act_id[i]),\n",
    "                ignore_index=True)\n",
    "               \n",
    "        else:\n",
    "            print('sample_'+str(i)+'was excluded')\n",
    "    print('finish_test')\n",
    "    return train, test\n",
    "\n",
    "\n",
    "## utility fimction to activate load_dataset function \n",
    "def extract_features_main(input_root,output_root):\n",
    "    # insert ind_train = 780 and ind_test = 290 for a short run of the feature extraction module\n",
    "    ind_train = 0\n",
    "    ind_test = 0\n",
    "    test = pd.DataFrame()\n",
    "    train = pd.DataFrame()\n",
    "    train,test = load_dataset(input_root,train,test,ind_train,ind_test)\n",
    "    train.to_csv(output_root+'train_new.csv')\n",
    "    test.to_csv(output_root+'test_new.csv')\n",
    "    \n",
    "#This code allow control on executing the model. \n",
    "#inpur root - where HARP database is saved in folder\n",
    "input_root = r'C:/Users/Yair/Documents/Airtasker/Akhila/HAPT Data Set/RawData/'\n",
    "#Output root - where to store fetures . using the same path to lunch them for in RandForest_model \n",
    "output_root = r'C:\\Users\\Yair\\Documents\\Airtasker\\Akhila\\HAPT Data Set\\Extracted_Features\\\\'\n",
    "### Deactivate this line to avoid feature extracture\n",
    "extract_features_main(input_root,output_root)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
